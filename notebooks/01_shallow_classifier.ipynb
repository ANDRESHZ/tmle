{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We start from loading images into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmle.dataloaders import ImageFoldersDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images in both, training and test sets, have different, unregular sizes. Thus, we will use transformers which first resize image to `256` px and then randomly crop them to target dimension of `224x224` px. After that, images will be converted to `torch.Tensors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the images in mini-batches and calculate the mean and standard deviations for each of the RGB channels. Obtained values will be used during normalization of inputs which will be passed do `SVM` and `CNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFoldersDataset(\n",
    "    path_to_data='../data/cpu/train',\n",
    "    transform=simple_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that even for small images (ie. `(224, 224, 3)`) calculating means of each RGB channel for dataset of reasonable size (ie. `17k`) would required operating on vectors of size `17000 * 224 * 224 * 3`. In order to increase the speed of calculation we performed calculations over mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "means, stds = defaultdict(list), defaultdict(list)\n",
    "counter = 0\n",
    "for data in dataset.loader(batch_size=170):\n",
    "    images, _ = data\n",
    "    for channel in [0, 1, 2]:\n",
    "        means[channel].append(images[:, channel, :, :].mean().item())\n",
    "        stds[channel].append(images[:, channel, :, :].std().item())\n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        print('Mean calculated for {n} batches'.format(n=counter / (17000 / 170)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [np.mean(means[channel]) for channel in [0, 1, 2]]\n",
    "stds = [np.mean(stds[channel]) for channel in [0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=means, std=stds)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_normalized = ImageFoldersDataset(\n",
    "    path_to_data='../data/cpu/train/',\n",
    "    transform=simple_transform\n",
    ")\n",
    "if SAMPLE:\n",
    "    X_train, y_train = dataset_normalized.load_all_images()\n",
    "    random_sample_idx = np.random.randint(low=0, high=len(X_train), size=SAMPLE)\n",
    "    X_train, y_train = X_train[random_sample_idx], y_train[random_sample_idx]\n",
    "else:\n",
    "    X_train, y_train = dataset_normalized.load_all_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Important note about reproducibility***.\n",
    "\n",
    "Completely reproducible results are not guaranteed across PyTorch releases, individual commits or different platforms. Furthermore, results need not be reproducible between CPU and GPU executions, even when using identical seeds.\n",
    "\n",
    "However, in order to make computations deterministic on specific problem on one specific platform and Pytorch release, there are a couple of steps to take.\n",
    "\n",
    "There are two pseudorandom number generators involved in PyTorch, which we had to seed manually to made runs reproducible. We implemented `tmle.dataloaders.ImageFolderDataset` setting seed as follows:\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ogranicz zbiór danych na potrzeby testów.\n",
    "\n",
    "    idx = np.random.randint(low=0, high=17000, size=17000)\n",
    "    X_train, y_train = images[idx], labels[idx]\n",
    "\n",
    "    del(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmle.transformers import HOGTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('hog', HOGTransformer(\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(12, 12),\n",
    "        cells_per_block=(1, 1))\n",
    "    ),\n",
    "    ('svm', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train_preds = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, balanced_accuracy_score\n",
    "\n",
    "print('Accuracy: {acc:.5f}. Balanced accuracy: {bal_acc:.5f}'.format(\n",
    "    acc=accuracy_score(y_train, y_train_preds),\n",
    "    bal_acc=balanced_accuracy_score(y_train, y_train_preds)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFoldersDataset(\n",
    "    path_to_data='../data/cpu/test/',\n",
    "    transform=simple_transform\n",
    ")\n",
    "X_test, y_test = test_dataset.load_all_images()\n",
    "y_test_preds = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {acc:.5f}. Balanced accuracy: {bal_acc:.5f}'.format(\n",
    "    acc=accuracy_score(y_test, y_test_preds),\n",
    "    bal_acc=balanced_accuracy_score(y_test, y_test_preds)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from definition of `Pipeline` which will be fed with parameters sampled from *hyperparameters space*. Our `Pipeline` consists of three steps:\n",
    "\n",
    "* `HOGTransformer`: implements method of transforming images into features vector based on histograms of oriented gradients,\n",
    "* `PCA`: reduces dimensionality of features vector outputed by `HOGTransformer`. In some scenarios the final features vector may have dimensions that will be hard to train on single-CPU machine,\n",
    "* `LinearSVC`: classifies the images. It scales good in terms of both: number of instances and number of features. We will be optimizing the value of *regularization* parameters and experimenting with different loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('hog', HOGTransformer()),\n",
    "    ('pca', PCA()),\n",
    "    ('svm', LinearSVC(max_iter=50000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters space\n",
    "\n",
    "Our definition of *hyperparameters space* encourages `TPE` algorithm to suggest `Pipelines` which differs not only in terms of classifier, but also in terms of operations applied to data in *preprocessing* stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import tpe, fmin, hp, Trials, STATUS_OK\n",
    "\n",
    "space = dict()\n",
    "space['hog__orientations'] = hp.choice('orientations', [9, 12, 18])\n",
    "space['hog__pixels_per_cell'] = hp.choice('pixels_per_cell', [(8, 8), (12, 12), (24, 24)])\n",
    "space['hog__cells_per_block'] = hp.choice('cells_per_block', [(1, 1), (2, 2), (4, 4)])\n",
    "space['hog__block_norm'] = hp.choice('block_norm', ['L1', 'L2-Hys'])\n",
    "space['pca__n_components'] = hp.choice('n_components', np.arange(50, 550, 50))\n",
    "space['svm__loss'] = hp.choice('loss', ['hinge', 'squared_hinge'])\n",
    "space['svm__C'] = hp.uniform('C', 0.001, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct experiments\n",
    "\n",
    "We use:\n",
    "\n",
    "* `sklearn.model_selection.StratifiedKFold` because of class imbalance present in the training set (we set the `n_splits` to `3`),\n",
    "* `sklearn.metrics.balanced_accuracy_score` to measure the performance of given classifier on both: training and validation sets. We try to minimize the objective with return score calculated as `1 - balanced_accuracy_score(validation_set)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmle.model_selection import ClassifierOptimizer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "clf_optim = ClassifierOptimizer(\n",
    "    classifier=pipe,\n",
    "    space=space,\n",
    "    metric=balanced_accuracy_score\n",
    ")\n",
    "clf_optim.find_best_params(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    experiments_path='../experiments/',\n",
    "    experiments_name='shallow_clf_tpe_pipeline',\n",
    "    max_evals=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmle",
   "language": "python",
   "name": "tmle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
